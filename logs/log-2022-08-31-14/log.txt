Logging to /Users/guyzamberg/PycharmProjects/git/AnomalyDiffusion/logs/log-2022-08-31-14
creating model and diffusion...
creating data loader...
training...
----------------------
| loss    | 1.1      |
| loss_q0 | 1.05     |
| loss_q1 | 1.24     |
| loss_q2 | 1.04     |
| loss_q3 | 1.13     |
| mse     | 1.1      |
| mse_q0  | 1.05     |
| mse_q1  | 1.24     |
| mse_q2  | 1.04     |
| mse_q3  | 1.13     |
| step    | 0        |
----------------------
----------------------
| loss    | 0.698    |
| loss_q0 | 0.827    |
| loss_q1 | 0.663    |
| loss_q2 | 0.645    |
| loss_q3 | 0.653    |
| mse     | 0.698    |
| mse_q0  | 0.827    |
| mse_q1  | 0.663    |
| mse_q2  | 0.645    |
| mse_q3  | 0.653    |
| step    | 200      |
----------------------
----------------------
| loss    | 0.247    |
| loss_q0 | 0.531    |
| loss_q1 | 0.172    |
| loss_q2 | 0.145    |
| loss_q3 | 0.147    |
| mse     | 0.247    |
| mse_q0  | 0.531    |
| mse_q1  | 0.172    |
| mse_q2  | 0.145    |
| mse_q3  | 0.147    |
| step    | 400      |
----------------------
----------------------
| loss    | 0.144    |
| loss_q0 | 0.454    |
| loss_q1 | 0.0567   |
| loss_q2 | 0.0373   |
| loss_q3 | 0.0372   |
| mse     | 0.144    |
| mse_q0  | 0.454    |
| mse_q1  | 0.0567   |
| mse_q2  | 0.0373   |
| mse_q3  | 0.0372   |
| step    | 600      |
----------------------
----------------------
| loss    | 0.131    |
| loss_q0 | 0.446    |
| loss_q1 | 0.0349   |
| loss_q2 | 0.0167   |
| loss_q3 | 0.0177   |
| mse     | 0.131    |
| mse_q0  | 0.446    |
| mse_q1  | 0.0349   |
| mse_q2  | 0.0167   |
| mse_q3  | 0.0177   |
| step    | 800      |
----------------------
----------------------
| loss    | 0.127    |
| loss_q0 | 0.442    |
| loss_q1 | 0.034    |
| loss_q2 | 0.0155   |
| loss_q3 | 0.0158   |
| mse     | 0.127    |
| mse_q0  | 0.442    |
| mse_q1  | 0.034    |
| mse_q2  | 0.0155   |
| mse_q3  | 0.0158   |
| step    | 1e+03    |
----------------------
----------------------
| loss    | 0.128    |
| loss_q0 | 0.444    |
| loss_q1 | 0.0333   |
| loss_q2 | 0.0148   |
| loss_q3 | 0.0154   |
| mse     | 0.128    |
| mse_q0  | 0.444    |
| mse_q1  | 0.0333   |
| mse_q2  | 0.0148   |
| mse_q3  | 0.0154   |
| step    | 1.2e+03  |
----------------------
----------------------
| loss    | 0.122    |
| loss_q0 | 0.425    |
| loss_q1 | 0.0324   |
| loss_q2 | 0.0142   |
| loss_q3 | 0.0144   |
| mse     | 0.122    |
| mse_q0  | 0.425    |
| mse_q1  | 0.0324   |
| mse_q2  | 0.0142   |
| mse_q3  | 0.0144   |
| step    | 1.4e+03  |
----------------------
----------------------
| loss    | 0.124    |
| loss_q0 | 0.435    |
| loss_q1 | 0.0328   |
| loss_q2 | 0.0143   |
| loss_q3 | 0.0145   |
| mse     | 0.124    |
| mse_q0  | 0.435    |
| mse_q1  | 0.0328   |
| mse_q2  | 0.0143   |
| mse_q3  | 0.0145   |
| step    | 1.6e+03  |
----------------------
----------------------
| loss    | 0.128    |
| loss_q0 | 0.448    |
| loss_q1 | 0.0333   |
| loss_q2 | 0.0139   |
| loss_q3 | 0.0142   |
| mse     | 0.128    |
| mse_q0  | 0.448    |
| mse_q1  | 0.0333   |
| mse_q2  | 0.0139   |
| mse_q3  | 0.0142   |
| step    | 1.8e+03  |
----------------------
----------------------
| loss    | 0.124    |
| loss_q0 | 0.442    |
| loss_q1 | 0.0324   |
| loss_q2 | 0.0132   |
| loss_q3 | 0.0131   |
| mse     | 0.124    |
| mse_q0  | 0.442    |
| mse_q1  | 0.0324   |
| mse_q2  | 0.0132   |
| mse_q3  | 0.0131   |
| step    | 2e+03    |
----------------------
----------------------
| loss    | 0.122    |
| loss_q0 | 0.435    |
| loss_q1 | 0.0333   |
| loss_q2 | 0.0133   |
| loss_q3 | 0.0132   |
| mse     | 0.122    |
| mse_q0  | 0.435    |
| mse_q1  | 0.0333   |
| mse_q2  | 0.0133   |
| mse_q3  | 0.0132   |
| step    | 2.2e+03  |
----------------------
----------------------
| loss    | 0.122    |
| loss_q0 | 0.431    |
| loss_q1 | 0.0334   |
| loss_q2 | 0.0135   |
| loss_q3 | 0.0137   |
| mse     | 0.122    |
| mse_q0  | 0.431    |
| mse_q1  | 0.0334   |
| mse_q2  | 0.0135   |
| mse_q3  | 0.0137   |
| step    | 2.4e+03  |
----------------------
